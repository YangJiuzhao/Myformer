Args in experiment:
Namespace(model='former', data='m1999m', root_path='./datasets/', data_path='m1999m.csv', data_split=[0.7, 0.1, 0.2], checkpoints='./checkpoints/', in_len=672, out_len=672, seg_lens='12,24,36,48,72', data_dim=5, d_model=256, d_ff=512, n_heads=4, a_layers=4, dropout=0.4, baseline=False, num_workers=0, batch_size=32, train_epochs=20, patience=3, learning_rate=0.0001, lradj='type1', itr=1, save_pred=False, use_gpu=True, gpu=1, use_multi_gpu=False, devices='0,1')
Use GPU: cuda:1
>>>>>>>start training : former_m1999m_il672_ol672_sl12,24,36,48,72_dm256_nh4_el4_itr0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6720
val 482
test 1633
	iters: 100, epoch: 1 | loss: 1.1622416
	speed: 0.2482s/iter; left time: 1017.8624s
	iters: 200, epoch: 1 | loss: 0.9458672
	speed: 0.2375s/iter; left time: 950.2582s
Epoch: 1 cost time: 50.67039465904236
Epoch: 1, Steps: 210 | Train Loss: 2.1366721 Vali Loss: 0.5947160 Test Loss: 1.5746248
Validation loss decreased (inf --> 0.594716).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.8349863
	speed: 0.2359s/iter; left time: 917.6956s
	iters: 200, epoch: 2 | loss: 0.7168859
	speed: 0.2519s/iter; left time: 954.8799s
Epoch: 2 cost time: 52.15428376197815
Epoch: 2, Steps: 210 | Train Loss: 0.8853128 Vali Loss: 0.5822159 Test Loss: 1.3520897
Validation loss decreased (0.594716 --> 0.582216).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7536743
	speed: 0.2363s/iter; left time: 869.8525s
	iters: 200, epoch: 3 | loss: 0.7224448
	speed: 0.2441s/iter; left time: 874.0509s
Epoch: 3 cost time: 50.551636695861816
Epoch: 3, Steps: 210 | Train Loss: 0.7615836 Vali Loss: 0.5049251 Test Loss: 1.3297493
Validation loss decreased (0.582216 --> 0.504925).  Saving model ...
	iters: 100, epoch: 4 | loss: 0.7547164
	speed: 0.2297s/iter; left time: 797.4374s
	iters: 200, epoch: 4 | loss: 0.7915462
	speed: 0.2390s/iter; left time: 805.5231s
Epoch: 4 cost time: 49.27952694892883
Epoch: 4, Steps: 210 | Train Loss: 0.7200717 Vali Loss: 0.5045087 Test Loss: 1.5228435
Validation loss decreased (0.504925 --> 0.504509).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 5 | loss: 0.5543951
	speed: 0.2350s/iter; left time: 766.3463s
	iters: 200, epoch: 5 | loss: 0.5669080
	speed: 0.2642s/iter; left time: 835.2394s
Epoch: 5 cost time: 51.987483739852905
Epoch: 5, Steps: 210 | Train Loss: 0.6664691 Vali Loss: 0.5328865 Test Loss: 1.6669594
EarlyStopping counter: 1 out of 3
	iters: 100, epoch: 6 | loss: 0.6353288
	speed: 0.2266s/iter; left time: 691.3687s
	iters: 200, epoch: 6 | loss: 0.6214132
	speed: 0.2357s/iter; left time: 695.4504s
Epoch: 6 cost time: 48.38556742668152
Epoch: 6, Steps: 210 | Train Loss: 0.6441390 Vali Loss: 0.5773697 Test Loss: 1.7584681
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 7 | loss: 0.6481289
	speed: 0.2642s/iter; left time: 750.5085s
	iters: 200, epoch: 7 | loss: 0.6114133
	speed: 0.2231s/iter; left time: 611.4032s
Epoch: 7 cost time: 51.00397562980652
Epoch: 7, Steps: 210 | Train Loss: 0.6145222 Vali Loss: 0.5808094 Test Loss: 1.7939391
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : former_m1999m_il672_ol672_sl12,24,36,48,72_dm256_nh4_el4_itr0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1633
mse:1.5112416744232178, mae:1.0605854988098145
