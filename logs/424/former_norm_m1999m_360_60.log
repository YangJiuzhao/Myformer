Args in experiment:
Namespace(model='former', data='m1999m', root_path='./datasets/', data_path='m1999m.csv', data_split=[0.7, 0.1, 0.2], checkpoints='./checkpoints/', in_len=360, out_len=60, seg_lens='6,10,15,20,30,60', data_dim=5, d_model=256, d_ff=512, n_heads=4, a_layers=3, dropout=0.4, baseline=False, fc_dropout=0.05, head_dropout=0.0, patch_len=12, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, freq='m', embed_type=0, enc_in=7, dec_in=7, c_out=7, e_layers=2, d_layers=1, moving_avg=25, factor=1, distil=True, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=0, batch_size=32, train_epochs=100, patience=3, learning_rate=0.0001, lradj='type1', itr=1, save_pred=False, use_gpu=True, gpu=1, use_multi_gpu=False, devices='0,1')
Use GPU: cuda:1
>>>>>>>start training : former_m1999m_il360_ol60_sl6,10,15,20,30,60_dm256_nh4_el3_itr0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7644
val 1094
test 2245
	iters: 100, epoch: 1 | loss: 0.4370783
	speed: 0.4331s/iter; left time: 10307.4669s
	iters: 200, epoch: 1 | loss: 0.3922502
	speed: 0.4152s/iter; left time: 9841.2400s
Epoch: 1 cost time: 100.24903917312622
Epoch: 1, Steps: 239 | Train Loss: 0.4992346 Vali Loss: 0.3051777 Test Loss: 0.4085829
Validation loss decreased (inf --> 0.305178).  Saving model ...
	iters: 100, epoch: 2 | loss: 0.3819865
	speed: 0.3871s/iter; left time: 9119.8782s
	iters: 200, epoch: 2 | loss: 0.4599957
	speed: 0.3922s/iter; left time: 9201.1997s
Epoch: 2 cost time: 94.39146852493286
Epoch: 2, Steps: 239 | Train Loss: 0.4137325 Vali Loss: 0.2872978 Test Loss: 0.3895710
Validation loss decreased (0.305178 --> 0.287298).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3030310
	speed: 0.3988s/iter; left time: 9301.0566s
	iters: 200, epoch: 3 | loss: 0.3297431
	speed: 0.4143s/iter; left time: 9620.4664s
Epoch: 3 cost time: 97.96681880950928
Epoch: 3, Steps: 239 | Train Loss: 0.3920963 Vali Loss: 0.2849832 Test Loss: 0.3925054
Validation loss decreased (0.287298 --> 0.284983).  Saving model ...
	iters: 100, epoch: 4 | loss: 0.3766778
	speed: 0.3869s/iter; left time: 8930.5149s
	iters: 200, epoch: 4 | loss: 0.4415077
	speed: 0.4438s/iter; left time: 10199.4919s
Epoch: 4 cost time: 104.31192469596863
Epoch: 4, Steps: 239 | Train Loss: 0.3841801 Vali Loss: 0.2896700 Test Loss: 0.3893025
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 5 | loss: 0.3971544
	speed: 0.5263s/iter; left time: 12022.9766s
	iters: 200, epoch: 5 | loss: 0.4215797
	speed: 0.5138s/iter; left time: 11685.5975s
Epoch: 5 cost time: 121.67081189155579
Epoch: 5, Steps: 239 | Train Loss: 0.3751472 Vali Loss: 0.2867879 Test Loss: 0.3868198
EarlyStopping counter: 2 out of 3
	iters: 100, epoch: 6 | loss: 0.3943813
	speed: 0.5588s/iter; left time: 12632.7768s
	iters: 200, epoch: 6 | loss: 0.4323255
	speed: 0.5440s/iter; left time: 12243.2675s
Epoch: 6 cost time: 131.54399967193604
Epoch: 6, Steps: 239 | Train Loss: 0.3723275 Vali Loss: 0.2855885 Test Loss: 0.3845128
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : former_m1999m_il360_ol60_sl6,10,15,20,30,60_dm256_nh4_el3_itr0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2245
mse:0.356852263212204, mae:0.3030721843242645
